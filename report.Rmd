---
title: "Pratical Machine Learning - Project"
author: "Flavio Barros"
date: "27 de setembro de 2015"
output: html_document
---

# Introduction

The dataset, that you can find [here](http://groupware.les.inf.puc-rio.br/har), is a dataset about movements in exercises. The objective here is create a machine learning model able to predict as correctly as possible if a movement is being done right. As you will see this dataset is noisy with lots of garbage variables.

# Preparation

As i will describe at the comments, i had to remove lots variables with too much NA's.  Just with this simple procedure and a simple tree from CART algorithm, i got 17/20 at project submission. 

```{r, eval = F}
## Loading packages
library(readr)
library(caret)

############################### DATA PREPARATION ##########################################
## Reading training and testing 
treino <- read_csv(file = 'pml-training.csv')
teste <- read_csv(file = 'pml-testing.csv')

## Removing variables with too much NA
## Function to count NA per column
conta_na <- function(x) {sum(is.na(x))}

## Apply function to get NA fraction
sapply(treino, conta_na)

## Selecting variables with no more then 20% of NA
seletor <- sapply(treino, conta_na) < 0.2

## Selecting variables
treino <- subset(treino, select = seletor)
treino <- treino[,-1]
nzv <- nearZeroVar(treino, saveMetrics= TRUE)
treino <- treino[,!nzv$nzv]
treino$classe <- as.factor(treino$classe)

## Retrieving variables names to select the same from test set
colunas <- colnames(treino)
teste <- subset(teste, select = colnames(teste) %in% colunas)
```

# First model

As you can see i did't use caret yet, neither cv to evaluate the model.

```{r, eval = F}
library(rpart)

arvore <- rpart(classe ~ ., data = treino)
predito <- predict(arvore, teste, 'class')
```

# Second model and PCA
Just to try something more, I used PCA to all numerical variables and using all the components up to 90% of variance. Instead of CART I opted for multinomial logistic regression.

```{r, eval = F}
## With just data cleaning and this simple model i got 17/20.

##########################################################################################
## Applying PCA and removing noisy variables like timestamp
treino$classe <- as.factor(treino$classe)
treino <- treino[,-c(1:4)]

## Saving column names to remove from test set too
colunas <- colnames(treino)
teste <- subset(teste, select = colnames(teste) %in% colunas)

## PCA with princomp
pc <- princomp(treino[,-53], cor = T)
treino_pc <- pc$scores[1:47]

## Including class variable
treino_pc$classe <- treino$classe

## Fitting a multinomial logistic regression model with 90% PCA components
ctrl <- trainControl(method = 'cv', repeats = 1, 
                     verboseIter = T, classProbs = T)

## Multinomial logistic regression model
multnomlogistic <- train(classe ~., data = treino, method = 'multinom', trainControl = ctrl)
predito <- predict(multnomlogistic, teste)
```

and got reasonable success of about 63%. BUT, i didn't consider correlated variables.

# Third model 

At this time i removed correlated variables (correlation over 0.85) and didn't apply PCA. I used randomForest instead of multinomial logistic regression and got Acc = 0.997. With this model i got 20/20.

```{r, eval=FALSE}
## Applying PCA and removing noisy variables like timestamp
treino$classe <- as.factor(treino$classe)
## Saving user name that can be a predictive power
user_name = treino$user_name

## Removing user name and timestamp variables
treino <- treino[,-c(1:4)]

## Finding correlations
correlated = findCorrelation(cor(treino[,-53]), cutoff = 0.85, verbose = T)

## Removing correlated variables
treino <- treino[,-correlated]

## Add user_name again
treino$user_name <- user_name

## Saving column names to remove from test set too
colunas <- colnames(treino)
teste <- subset(teste, select = colnames(teste) %in% colunas)

## Evaluationg the randomForest with cross validation
## Fitting a randomForest - correlated variables + PCA (90% components)
ctrl <- trainControl(method = 'cv', repeats = 1, 
                     verboseIter = T)

## Multinomial logistic regression model
rfFit <- train(classe ~., data = treino, method = 'rf', trainControl = ctrl)
predito <- predict(rfFit, teste)
```

This model took more then 10 hours to run! So i will load it here and show the evaluation:

```{r}
load(file = 'rfFit.rda')
rfFit
```

# Conclusion

I think this task was all about data preparation. This dataset is noisy and i think that with basic data preparation, plus a good model, like randomForest, it's possible to build an almost perfect classifier.
